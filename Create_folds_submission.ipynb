{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/data/rustem/landmarks/data'\n",
    "path_to_submit = '/data/rustem/landmarks/data/checkpoints/resnext50_32x4d_06_folds/submit0_5.csv'\n",
    "fold_index = 6\n",
    "test_predictions_list = []\n",
    "for i in range(6):\n",
    "    path_to_predictions = f'/data/rustem/landmarks/data/checkpoints/resnext50_32x4d_0{fold_index}_fold{i}/resnext50_32x4d_test_predictions.pkl'\n",
    "    test_predictions_list.append(pickle.load(open(path_to_predictions, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_HEADER = \"file_name,Point_M0_X,Point_M0_Y,Point_M1_X,Point_M1_Y,Point_M2_X,Point_M2_Y,Point_M3_X,Point_M3_Y,Point_M4_X,Point_M4_Y,Point_M5_X,Point_M5_Y,Point_M6_X,Point_M6_Y,Point_M7_X,Point_M7_Y,Point_M8_X,Point_M8_Y,Point_M9_X,Point_M9_Y,Point_M10_X,Point_M10_Y,Point_M11_X,Point_M11_Y,Point_M12_X,Point_M12_Y,Point_M13_X,Point_M13_Y,Point_M14_X,Point_M14_Y,Point_M15_X,Point_M15_Y,Point_M16_X,Point_M16_Y,Point_M17_X,Point_M17_Y,Point_M18_X,Point_M18_Y,Point_M19_X,Point_M19_Y,Point_M20_X,Point_M20_Y,Point_M21_X,Point_M21_Y,Point_M22_X,Point_M22_Y,Point_M23_X,Point_M23_Y,Point_M24_X,Point_M24_Y,Point_M25_X,Point_M25_Y,Point_M26_X,Point_M26_Y,Point_M27_X,Point_M27_Y,Point_M28_X,Point_M28_Y,Point_M29_X,Point_M29_Y\\n\"\n",
    "def create_submission(path_to_data, test_predictions_list, path_to_submission_file):\n",
    "    test_dir = os.path.join(path_to_data, \"test\")\n",
    "\n",
    "    output_file = path_to_submission_file\n",
    "    wf = open(output_file, 'w')\n",
    "    wf.write(SUBMISSION_HEADER)\n",
    "\n",
    "    mapping_path = os.path.join(test_dir, 'test_points.csv')\n",
    "    mapping = pd.read_csv(mapping_path, delimiter='\\t')\n",
    "\n",
    "    for i, row in tqdm.tqdm(mapping.iterrows()):\n",
    "        file_name = row[0]\n",
    "        point_index_list = np.array(eval(row[1]))\n",
    "        needed_points = []\n",
    "        for test_predictions in test_predictions_list:\n",
    "            points_for_image = test_predictions['landmarks'][i]\n",
    "            needed_points.append(points_for_image[point_index_list])\n",
    "        needed_points = np.stack(needed_points, axis=0)\n",
    "        needed_points = np.median(needed_points, axis=0).astype(np.int)\n",
    "            \n",
    "        wf.write(file_name + ',' + ','.join(map(str, needed_points.reshape(2 * len(point_index_list)))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99819it [00:44, 2257.79it/s]\n"
     ]
    }
   ],
   "source": [
    "create_submission(path_to_data, test_predictions_list, path_to_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PTS = 971\n",
    "model = models.resnext50_32x4d(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2 * NUM_PTS, bias=True)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/data/rustem/landmarks/data'\n",
    "model_weights = []\n",
    "for i in range(5):\n",
    "    path_to_predictions = f'/data/rustem/landmarks/data/checkpoints/resnext50_32x4d_00_fold{i}/resnext50_32x4d_best.pth'\n",
    "    model_weights.append(torch.load(path_to_predictions, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:56<00:00,  5.71it/s]\n"
     ]
    }
   ],
   "source": [
    "final_weights = model_weights[0].copy()\n",
    "for param_name in tqdm.tqdm(model_weights[0]):\n",
    "    all_weights = torch.stack([model_weights[i][param_name] for i in range(5)])\n",
    "    if all_weights.dtype == torch.int64:\n",
    "        mean_weight = torch.mean(all_weights.float(), dim=0).long()\n",
    "    else:\n",
    "        mean_weight = torch.mean(all_weights, dim=0)\n",
    "    final_weights[param_name] = mean_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_model_weights = '/data/rustem/landmarks/data/checkpoints/weight_average/weight_average.pth'\n",
    "with open(path_to_save_model_weights, 'wb') as fp:\n",
    "    torch.save(model.state_dict(), fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
